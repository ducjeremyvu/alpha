{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "938ee9dd",
   "metadata": {},
   "source": [
    "# CTrader Pepperstone Data Timezone Adjustments\n",
    "\n",
    "## Problem Analysis \n",
    "\n",
    "I use data that's according to the timezone where I live in. That is Germany. In the summer it is UTC+2 and during winter it changes to UTC+1. Some places do not adopt such Day Time Saving (DTS) regime. Some other places adopt it a week later. It brings with a lot of confusions so it would make sense assigning the timezone parameter to such data objects to then being able to convert them to the needed timezones. With that I can target US Open regardless of my location, target Tokyo opens regardles off DTS. \n",
    "\n",
    "## Details \n",
    "\n",
    " - data from Ctrader, CTrader with pepperstone always ran at UTC+2\n",
    " - so the idea is to assign the datetime with timezone parameter\n",
    " - the idea came when i wanted to see price differences between difference opens, that would show some sort of sentiment of global player. it would be easier targeting US Open by just converting to US open time. \n",
    "\n",
    "\n",
    "\n",
    "## Thoughts\n",
    "\n",
    "I first need to convert it to something like timezone \n",
    "then convert timezones \n",
    "but i have to do it efficiently \n",
    "\n",
    "what do i wanna do? \n",
    "\n",
    "for each day:  \n",
    "    get the us close value of d-1 \n",
    "    get value during \n",
    "\n",
    "\n",
    "\n",
    "just using the value for the open time wouldnt make sense, i need to capture the sentiment\n",
    "nah \n",
    "what position is the one with the highest aussagekraft\n",
    "well actually i need to check a range, then \n",
    "\n",
    "range of toyko open, maybe its too engineerd, point in time mgiht be already sufficient. \n",
    "i dont know yet. i need to figure this out myself i guess \n",
    "\n",
    "what do i wanna see here? \n",
    "the idea is to capture movements that are outside of us business hours, that would be other locations \n",
    "and maybe their sentiment might give clues on how the next day could evolve. its a chain of sentiments through the globe, thats the idea. thats the idea chat gpt actually set to mind, so i definitely need to check if this makes sense from a logic standpoint. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca6e86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "aef83244-914e-4df6-93a5-1d1d7f44bb6b",
       "rows": [
        [
         "0",
         "2019-12-25 23:00"
        ],
        [
         "1",
         "2019-12-25 23:01"
        ],
        [
         "2",
         "2019-12-25 23:02"
        ],
        [
         "3",
         "2019-12-25 23:03"
        ],
        [
         "4",
         "2019-12-25 23:04"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/plain": [
       "0    2019-12-25 23:00\n",
       "1    2019-12-25 23:01\n",
       "2    2019-12-25 23:02\n",
       "3    2019-12-25 23:03\n",
       "4    2019-12-25 23:04\n",
       "Name: time, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import pandas_ta as ta\n",
    "from edge_tools.ohlcv import normalize_ohlcv\n",
    "\n",
    "# Load the data\n",
    "# Ensure the path is correct and points to your CSV file\n",
    "# Example: data_path = \"./data/US500_Minute_20250821_0926.csv\"\n",
    "data_path = \"./data/US500_Minute_20250821_0926.csv\"\n",
    "\n",
    "# Read the CSV file\n",
    "# Adjust the path as necessary\n",
    "# If the file is large, consider using chunksize or dtypes to optimize memory usage\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "\n",
    "data = normalize_ohlcv(data, style=\"lowercase\")\n",
    "\n",
    "\n",
    "data[\"time\"].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff432a38",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
